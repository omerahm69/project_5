{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(Data Collection)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and save as raw data, prepare it for further process\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file-authentication token\n",
        "\n",
        "## Outputs\n",
        "\n",
        "*  Generate Dataset:inputs/datasets/cherry-leaves_dataset\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\python_projects\\\\project_5\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\python_projects\\\\project_5'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: kaggle in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (79.0.1)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: webencodings in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->kaggle) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "#install Kaggle \n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR']=os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: kaggle datasets download [-h] [-f FILE_NAME] [-p PATH] [-w] [--unzip]\n",
            "                                [-o] [-q]\n",
            "                                [dataset]\n",
            "kaggle datasets download: error: argument -d/--dataset: expected one argument\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \" \"\n",
        "DestinationFolder = \"inputs/cherry-leaves_dataset\"\n",
        "\n",
        "os.makedirs(DestinationFolder, exist_ok=True)\n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory: c:\\python_projects\\project_5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current Working Directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "DestinationFolder = os.path.abspath(\"inputs/cherry-leaves_dataset\")\n",
        "zip_file_path = os.path.join(DestinationFolder, \"cherry-leaves.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: File not found at c:\\python_projects\\project_5\\inputs\\cherry-leaves_dataset\\cherry-leaves.zip\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "DestinationFolder = os.path.abspath(\"inputs/cherry-leaves_dataset\")\n",
        "zip_file_path = os.path.join(DestinationFolder, \"cherry-leaves.zip\")\n",
        "\n",
        "if not os.path.exists(zip_file_path):\n",
        "    print(f\"Error: File not found at {zip_file_path}\")\n",
        "else:\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(DestinationFolder)\n",
        "        print(f\"Extracted: {zip_file_path}\")\n",
        "        \n",
        "        os.remove(zip_file_path)  # Remove the ZIP file after extraction\n",
        "        print(f\"Deleted: {zip_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting ZIP file: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Cleaning\n",
        " Check and remove non-image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    image_extenstion=('.png','.jpg','.jpeg', '.bmp')\n",
        "    folders=os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files=os.listdir(my_data_dir + '/' + folder)\n",
        "        # print (files)\n",
        "        i=[]\n",
        "        j=[]\n",
        "        for given_file in files:\n",
        "            if not given_file.lower().endswith(image_extenstion):\n",
        "                file_location=my_data_dir + '/' + folder + '/' + given_file\n",
        "                os.remove(file_location) #remove non image file\n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "        print(f\"Folder:{folder} - has image file\", len(j))\n",
        "        print(f\"Folder:{folder} - has image file\", len(i))\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder:healthy - has image file 0\n",
            "Folder:healthy - has image file 0\n",
            "Folder:powdery_mildew - has image file 0\n",
            "Folder:powdery_mildew - has image file 0\n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[WinError 5] Åtkomst nekad: 'inputs/cherry-leaves_dataset/cherry-leaves/test/healthy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mremove_non_image_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_data_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minputs/cherry-leaves_dataset/cherry-leaves\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mremove_non_image_file\u001b[39m\u001b[34m(my_data_dir)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m given_file.lower().endswith(image_extenstion):\n\u001b[32m     11\u001b[39m     file_location=my_data_dir + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + folder + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + given_file\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_location\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#remove non image file\u001b[39;00m\n\u001b[32m     13\u001b[39m     i.append(\u001b[32m1\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mPermissionError\u001b[39m: [WinError 5] Åtkomst nekad: 'inputs/cherry-leaves_dataset/cherry-leaves/test/healthy'"
          ]
        }
      ],
      "source": [
        "remove_non_image_file(my_data_dir='inputs/cherry-leaves_dataset/cherry-leaves')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split train validation test set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: joblib in c:\\users\\omer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.4.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
            "[notice] To update, run: C:\\Users\\omer\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "\n",
        "    # gets classes labels\n",
        "    labels = os.listdir(my_data_dir)  # it should get only the folder name\n",
        "    if 'test' in labels:\n",
        "        pass\n",
        "    else:\n",
        "        # create train, test folders with classes labels sub-folder\n",
        "        for folder in ['train', 'validation', 'test']:\n",
        "            for label in labels:\n",
        "                os.makedirs(name=my_data_dir + '/' + folder + '/' + label)\n",
        "\n",
        "        for label in labels:\n",
        "\n",
        "            files = os.listdir(my_data_dir + '/' + label)\n",
        "            random.shuffle(files)\n",
        "\n",
        "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "            count = 1\n",
        "            for file_name in files:\n",
        "                if count <= train_set_files_qty:\n",
        "                    # move a given file to the train set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/train/' + label + '/' + file_name)\n",
        "\n",
        "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                    # move a given file to the validation set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/validation/' + label + '/' + file_name)\n",
        "\n",
        "                else:\n",
        "                    # move given file to test set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/test/' + label + '/' + file_name)\n",
        "\n",
        "                count += 1\n",
        "\n",
        "            os.rmdir(my_data_dir + '/' + label)\n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_validation_test_images(\n",
        "    my_data_dir='inputs/cherry-leaves_dataset/cherry-leaves',\n",
        "    train_set_ratio=0.7,\n",
        "    validation_set_ratio=0.1,\n",
        "    test_set_ratio=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "healthy: 0 train, 0 validation, 0 test\n",
            "powdery_mildew: 0 train, 0 validation, 0 test\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "my_data_dir='inputs/cherry-leaves_dataset/cherry-leaves'\n",
        "classes=['healthy', 'powdery_mildew']\n",
        "splits=['train', 'validation', 'test']\n",
        "split_ratios=[0.7,0.1,0.2]\n",
        "\n",
        "# Make sure destination folders exist\n",
        "for split in splits:\n",
        "    for cls in classes:\n",
        "        split_path = os.path.join(my_data_dir, split, cls)\n",
        "        os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "    # Function to split and move images\n",
        "def split_and_move_images():\n",
        "    for cls in classes:\n",
        "        src_folder = os.path.join(my_data_dir, cls)\n",
        "        all_images = [f for f in os.listdir(src_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        random.shuffle(all_images)\n",
        "\n",
        "        total = len(all_images)\n",
        "        train_end = int(total * split_ratios[0])\n",
        "        val_end = train_end + int(total * split_ratios[1])\n",
        "\n",
        "        train_files = all_images[:train_end]\n",
        "        val_files = all_images[train_end:val_end]\n",
        "        test_files = all_images[val_end:]\n",
        "\n",
        "        for split, file_list in zip(splits, [train_files, val_files, test_files]):\n",
        "            for filename in file_list:\n",
        "                src_path = os.path.join(src_folder, filename)\n",
        "                dst_path = os.path.join(my_data_dir, split, cls, filename)\n",
        "                shutil.move(src_path, dst_path)\n",
        "\n",
        "        print(f\"{cls}: {len(train_files)} train, {len(val_files)} validation, {len(test_files)} test\")\n",
        "\n",
        "split_and_move_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
